# -*- coding: utf-8 -*-
"""Food-Classification(Inception_v3).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UZMw9-ZN10RH5H79WCkH_uGiGjQT7Cmo

#Kaggle
"""

from google.colab import files
files.upload()

! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets list

! kaggle datasets download -d kmader/food41

! unzip food41.zip

"""#Code"""

import os
import tensorflow as tf
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from pathlib import Path
import seaborn as sns
import numpy as np
import pandas as pd
import tensorflow.keras.applications.inception_v3
from sklearn.metrics import confusion_matrix , classification_report
from sklearn.model_selection import train_test_split
from tensorflow.keras.losses import categorical_crossentropy

# tf.keras.applications.inception_v3.InceptionV3

image_dir = Path('/content/images/apple_pie')
image_dir1 = Path('/content/images/baby_back_ribs')
image_dir2 = Path('/content/images/baklava')
image_dir3 = Path('/content/images/beef_carpaccio')
image_dir4 = Path('/content/images/beef_tartare')
image_dir5 = Path('/content/images/beet_salad')
image_dir6 = Path('/content/images/beignets')
image_dir7 = Path('/content/images/bibimbap')

filepaths = list(image_dir.glob(r'**/*.jpg'))
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

images = pd.concat([filepaths, labels], axis=1)

category_samples = []
for category in images['Label'].unique():
    category_slice = images.query("Label == @category")
    category_samples.append(category_slice.sample(1000, random_state=1))
image_df = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)
#=======================================================    1 =======================================================#

filepaths = list(image_dir1.glob(r'**/*.jpg'))
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

images = pd.concat([filepaths, labels], axis=1)

category_samples = []
for category in images['Label'].unique():
    category_slice = images.query("Label == @category")
    category_samples.append(category_slice.sample(1000, random_state=1))
image_df1 = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)
#=======================================================    2 =======================================================#

filepaths = list(image_dir2.glob(r'**/*.jpg'))
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

images = pd.concat([filepaths, labels], axis=1)

category_samples = []
for category in images['Label'].unique():
    category_slice = images.query("Label == @category")
    category_samples.append(category_slice.sample(1000, random_state=1))
image_df2 = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)
#=======================================================    3 =======================================================#
filepaths = list(image_dir3.glob(r'**/*.jpg'))
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

images = pd.concat([filepaths, labels], axis=1)

category_samples = []
for category in images['Label'].unique():
    category_slice = images.query("Label == @category")
    category_samples.append(category_slice.sample(1000, random_state=1))
image_df3 = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)
#=======================================================    4 =======================================================#
filepaths = list(image_dir4.glob(r'**/*.jpg'))
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

images = pd.concat([filepaths, labels], axis=1)

category_samples = []
for category in images['Label'].unique():
    category_slice = images.query("Label == @category")
    category_samples.append(category_slice.sample(1000, random_state=1))
image_df4 = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)
#=======================================================    5 =======================================================#

filepaths = list(image_dir5.glob(r'**/*.jpg'))
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

images = pd.concat([filepaths, labels], axis=1)

category_samples = []
for category in images['Label'].unique():
    category_slice = images.query("Label == @category")
    category_samples.append(category_slice.sample(1000, random_state=1))
image_df5 = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)
#=======================================================    6  =======================================================#
filepaths = list(image_dir6.glob(r'**/*.jpg'))
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

images = pd.concat([filepaths, labels], axis=1)

category_samples = []
for category in images['Label'].unique():
    category_slice = images.query("Label == @category")
    category_samples.append(category_slice.sample(1000, random_state=1))
image_df6 = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)
#=======================================================    7 =======================================================#
filepaths = list(image_dir7.glob(r'**/*.jpg'))
labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

images = pd.concat([filepaths, labels], axis=1)

category_samples = []
for category in images['Label'].unique():
    category_slice = images.query("Label == @category")
    category_samples.append(category_slice.sample(1000, random_state=1))
image_df7 = pd.concat(category_samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)
#=======================================================    1 =======================================================#

# from keras.applications.vgg16 import VGG16
# from keras.applications.vgg16 import preprocess_input, decode_predictions
# from keras.preprocessing import image
# from keras.layers import Input

df_row = pd.concat([image_df, image_df1 ,image_df2,image_df3,image_df4,image_df5,image_df6,image_df7])

train_df, test_df = train_test_split(df_row, train_size=0.7, shuffle=True, random_state=1)

train_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.inception_v3.preprocess_input,
        validation_split=0.4
)

test_generator = tf.keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=tf.keras.applications.inception_v3.preprocess_input,

)

"""Hidden Code here !
<!-- # new_generator= tf.keras.preprocessing.image.ImageDataGenerator(
#     featurewise_center=False,  # set input mean to 0 over the dataset
#     samplewise_center=False,  # set each sample mean to 0
#     featurewise_std_normalization=False,  # divide inputs by std of the dataset
#     samplewise_std_normalization=False,  # divide each input by its std
#     zca_whitening=False,  # apply ZCA whitening
#     rotation_range=45,  # randomly rotate images in the range (degrees, 0 to 180)
#     width_shift_range=0.125,  # randomly shift images horizontally (fraction of total width)
#     height_shift_range=0.125,  # randomly shift images vertically (fraction of total height)
#     horizontal_flip=True,  # randomly flip images
#     vertical_flip=False, # randomly flip images
#     rescale=1./255,
#     fill_mode='nearest',
#     validation_split=0.2,
# ) -->
"""

train_images = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='training'
)

val_images = train_generator.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_images = test_generator.flow_from_dataframe(
    dataframe=test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=False,
)

pretrained_model = tf.keras.applications.InceptionV3(
    input_shape=(229, 229, 3),
    include_top=False,
    weights='imagenet',
    pooling='avg'
)

pretrained_model.trainable = False

inputs = pretrained_model.input

x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)
x = tf.keras.layers.Dense(128, activation='relu')(x)
x = tf.keras.layers.Dropout(0.3)(x)
outputs = tf.keras.layers.Dense(8, activation='softmax')(x)

model = tf.keras.Model(inputs, outputs)


print(model.summary())

from tensorflow.keras.optimizers import Adam
model.compile(
    optimizer='adam',
    loss=tf.keras.losses.categorical_crossentropy,
    metrics=['accuracy']
)

history = model.fit(
    train_images,
    validation_data=val_images,
    epochs=25,
    callbacks=[
        tf.keras.callbacks.EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True
        )
    ]
)

results = model.evaluate(test_images, verbose=1)
print("Test Accuracy: {:.2f}%".format(results[1] * 100))

